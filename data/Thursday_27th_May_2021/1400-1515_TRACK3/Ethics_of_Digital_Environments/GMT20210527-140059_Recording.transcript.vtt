WEBVTT

1
00:00:00.089 --> 00:00:00.539
And just.

2
00:00:02.639 --> 00:00:16.379
Anna Nacher: That we are spanned across time zones so actually for me, it is good afternoon i'm not sure about you and since then it's been Grasser, is located in Chicago close to Chicago Illinois lauren and Rachel are.

3
00:00:17.250 --> 00:00:28.110
Anna Nacher: Close to Orlando Florida and justin is also London yeah although on usually close to London Los Angeles so um so we have several time zones, we have three.

4
00:00:29.490 --> 00:00:36.390
Anna Nacher: brilliant papers I picked a bit in your papers and i'm really looking forward to hear more about.

5
00:00:37.440 --> 00:00:39.360
Anna Nacher: Bands bence artwork.

6
00:00:41.190 --> 00:00:45.450
Anna Nacher: The endless don't score that also is on the display.

7
00:00:46.650 --> 00:00:53.670
Anna Nacher: In our exhibition copy and literature and then we'll progress and.

8
00:00:56.610 --> 00:00:57.480
Anna Nacher: And we'll be.

9
00:00:59.010 --> 00:01:03.210
Anna Nacher: Listening to lauren and Rachel talking about an.

10
00:01:04.230 --> 00:01:06.330
Anna Nacher: Interesting use of.

11
00:01:07.380 --> 00:01:20.370
Anna Nacher: tinder APP and I guess and finally justin about alternate reality games, the shroud, I was interested in some time ago, so i'm really looking forward to all three presentations because.

12
00:01:20.760 --> 00:01:35.250
Anna Nacher: There is some kind of and i'm wondering what kind of a common theme will be running through all the presentations It remains to be seen, and I think we can discuss later so Ben, the floor is yours, the virtual for all, the floor is yours.

13
00:01:36.330 --> 00:01:36.960
Ben Grosser: Thanks Anna.

14
00:01:45.600 --> 00:01:47.220
Ben Grosser: To find the right window there we go.

15
00:01:50.640 --> 00:01:53.130
Ben Grosser: Okay nice to see you all.

16
00:01:54.810 --> 00:01:58.500
Ben Grosser: see if I can actually see you all, while I do this here.

17
00:02:05.940 --> 00:02:08.370
Ben Grosser: All right, you all can see the presentation.

18
00:02:11.160 --> 00:02:11.640
Ben Grosser: Yes.

19
00:02:12.300 --> 00:02:13.290
Anna Nacher: Yes, we can see.

20
00:02:13.950 --> 00:02:17.820
Ben Grosser: Thanks so yeah nice to be here and.

21
00:02:19.200 --> 00:02:31.950
Ben Grosser: happy to be talking with you all so for many years now the smartphone has provided comfort and distraction during breaks and the regular flow of time.

22
00:02:32.670 --> 00:02:40.950
Ben Grosser: But perhaps no moment in modern history has provided such widespread breaks in the normal flow is the early pandemic of 2020.

23
00:02:41.760 --> 00:02:51.210
Ben Grosser: And eagerly awaiting anyone who reached for their phones over the last 14 months, where the social media platforms, a place many get their news from.

24
00:02:51.900 --> 00:03:04.740
Ben Grosser: But these sites are designed to inform they're designed to engage us and they want to show whatever they can to keep us on the site and perhaps nothing more engaged us in.

25
00:03:06.150 --> 00:03:20.160
Ben Grosser: than bad news, and so the combination of these factors, produced a proliferation of excessive bad news reading during the pandemic, a condition so common that it gained a new term doom scrolling.

26
00:03:21.210 --> 00:03:32.430
Ben Grosser: Down scrolling refers to the ways in which people find themselves regularly and, in some cases, almost in voluntarily scrolling bad news headlines on their phone.

27
00:03:32.940 --> 00:03:43.050
Ben Grosser: Often four hours each night in bed when they had meant to be sleeping and while we all need to stay on top of the news and case pandemic recommendations change.

28
00:03:43.590 --> 00:03:58.380
Ben Grosser: doom scrolling wasn't just a natural reaction to the news of the day it was an activity largely produced by social media interfaces designed to show us, whatever they could, in order to keep us engaged.

29
00:03:59.070 --> 00:04:10.590
Ben Grosser: And a primary mechanism central to do scrolling is the infinite scroll a dynamic interface design that makes sure the page a user is reading never ends.

30
00:04:11.100 --> 00:04:30.390
Ben Grosser: and its aim is to reduce friction, as well as to obscure surveillance infrastructure behind the scenes and anytime we find a platform working to reduce friction, it should generally be taken as a clue to look more closely to think about why it's reducing friction.

31
00:04:31.980 --> 00:04:44.280
Ben Grosser: interested in polled theorize about the object produced through such techniques as a Meta interface a layer between user and system that employees techniques like minimalist hiding.

32
00:04:44.670 --> 00:04:55.110
Ben Grosser: to blur the moderate monitoring and profiling such interfaces enable hiding the fact that while we read them they read us back.

33
00:04:56.070 --> 00:05:08.550
Ben Grosser: And their aim is to predict what will keep us they're transforming in this case human reading away from an active consumption into a sort of looping consumption of negative headlines.

34
00:05:11.670 --> 00:05:20.820
Ben Grosser: The cultural effects of interfaces is an ongoing subject in net are and electronic literature and I mentioned a number of works in my full paper.

35
00:05:22.470 --> 00:05:35.250
Ben Grosser: context so want to talk for a moment about an artwork of mine that fits within this frame and which investigates the cultural effects of doom scrolling and so work, called the endless doom scroll.

36
00:05:36.060 --> 00:05:44.910
Ben Grosser: it's an alternative interface that acts as a lens on our pandemic era software enabled collective descent into despair.

37
00:05:46.260 --> 00:05:56.850
Ben Grosser: released in summer of 2020 it presents itself as a simplified social media feed and each onion clickable button contains a short headline such as.

38
00:05:57.420 --> 00:06:07.470
Ben Grosser: All events canceled devastation worsens lockdowns imminent outbreak continues the numbers look bad things like that.

39
00:06:08.430 --> 00:06:23.490
Ben Grosser: And the only thing you can do with those headlines is scroll and no matter how long one scrolls or how fast the endless do scroll or will never stop presenting it's bad news headlines, they just keep coming.

40
00:06:24.540 --> 00:06:37.110
Ben Grosser: And the works primary technique can be argued, as one of reduction, the work distills news and social media sites down to their barest most generalized messages and interface conventions.

41
00:06:37.590 --> 00:06:46.110
Ben Grosser: headlines are simplified versions of real ones and the interface that presents them is reduced to its core interaction the infinite scroll.

42
00:06:47.790 --> 00:06:59.280
Ben Grosser: And so, through these tactics, the endless doing scroller deconstructs the doom scrolling Meta interface revealing how it's changing what and how we read in the digital and pandemic age.

43
00:07:01.890 --> 00:07:20.850
Ben Grosser: Feedback shows that, for some, it can create an opportunity for mindfulness about how they spend their time online for others, the peace enables a sort of exposure or substitution therapy a way to escape or replace what doom scrolling interfaces want from and do to us.

44
00:07:21.870 --> 00:07:34.140
Ben Grosser: And, through its reduction, the work counters the minute interfaces minimalist hiding with a sort of minimalist revealing a reduction that shows, rather than hines.

45
00:07:35.550 --> 00:07:44.670
Ben Grosser: And ultimately, what the endless doom scroller does is to show us how the software structures of social media change not only what we read, but how we read.

46
00:07:45.540 --> 00:08:00.240
Ben Grosser: As an a static reductive interface experience it provides renewed opportunities for agency within the systems we all find ourselves stuck in, in other words, when it comes to reading social media and the age of pandemic.

47
00:08:01.380 --> 00:08:07.080
Ben Grosser: whoops perhaps the only way out of too much doom scrolling is endless scrolling.

48
00:08:08.220 --> 00:08:08.580
Ben Grosser: Thanks.

49
00:08:14.070 --> 00:08:15.900
Anna Nacher: yeah I already asked.

50
00:08:17.460 --> 00:08:17.970
Anna Nacher: questions.

51
00:08:20.310 --> 00:08:20.850
Anna Nacher: later on.

52
00:08:23.730 --> 00:08:24.270
questions.

53
00:08:28.530 --> 00:08:31.050
Anna Nacher: Now i'm passing the torch.

54
00:08:32.490 --> 00:08:34.740
Anna Nacher: lauren or else do I pronounce your.

55
00:08:35.130 --> 00:08:41.820
Anna Nacher: Name okay yeah so Laura Morales and Rachel winter and we're delving into tinder.

56
00:08:48.000 --> 00:08:52.530
Lauren Rouse (she/they): hold on just a second I have like okay great and.

57
00:08:54.330 --> 00:08:54.600
Right.

58
00:08:55.800 --> 00:09:13.050
Lauren Rouse (she/they): hi everyone, my name is lauren rouse and I am here with my co author Rachel winter and we are presenting our paper called swype nights was fun, but useless and analysis of 10 there's a slight night and interactive foray into online dating.

59
00:09:16.380 --> 00:09:19.860
Lauren Rouse (she/they): So swipe nights was debuted and October.

60
00:09:21.000 --> 00:09:28.830
Lauren Rouse (she/they): and allowed tender users to navigate through a narrative based around the premise that they had three hours until the end of the world's.

61
00:09:29.280 --> 00:09:40.200
Lauren Rouse (she/they): Each Sunday, a new episode premiered and users had until midnight to play through the story so we're going to watch the little trailer that they have this oh sorry.

62
00:09:42.630 --> 00:09:43.110
Lauren Rouse (she/they): All right, we're good.

63
00:09:53.850 --> 00:09:56.670
Rachel Winter: I cannot hear any sound lauren yeah.

64
00:09:56.700 --> 00:09:57.660
We don't yeah.

65
00:09:58.980 --> 00:09:59.340
Lauren Rouse (she/they): Sorry.

66
00:10:01.410 --> 00:10:02.010
Lauren Rouse (she/they): Thanks Rachel.

67
00:10:13.530 --> 00:10:16.290
Rachel Winter: Still don't hear the sound I feel like the visuals are probably fine.

68
00:10:17.460 --> 00:10:17.850
Lauren Rouse (she/they): Okay.

69
00:10:22.650 --> 00:10:26.700
Anna Nacher: Okay, when you when you try it before the session sentence so.

70
00:10:27.330 --> 00:10:27.960
Lauren Rouse (she/they): yeah.

71
00:10:28.260 --> 00:10:29.010
So finding.

72
00:10:30.090 --> 00:10:42.180
Lauren Rouse (she/they): Okay, I was unsure if that would work but it's just a little 45 second trailer at talking about the kind of narratives that played through this entire adventure so.

73
00:10:42.780 --> 00:10:55.410
Lauren Rouse (she/they): Users choices that helped shaped not only the unfolding of the narrative but also contributed to potential matches with other tinder users, I divergence from tenders usual practice of matching users by proximity.

74
00:10:56.070 --> 00:11:02.760
Lauren Rouse (she/they): At the end of the gameplay users could post their results to their pro top profile for potential match users to see.

75
00:11:05.820 --> 00:11:16.350
Rachel Winter: So, because tinder facilitates a one to one communication through private messages we had to find a different approach to study user reactions, his wife night event because we didn't have access to those messages, obviously.

76
00:11:16.830 --> 00:11:28.620
Rachel Winter: So the reddit platform, and specifically the subreddit our tinder provides a space for tender users to post screenshots messages and bios as well as her reflect on their tinder experiences as a Community.

77
00:11:29.580 --> 00:11:36.960
Rachel Winter: So to collect data from that subreddit we use the free webs web scraper parse hub to collect data from the top 50.

78
00:11:37.260 --> 00:11:47.490
Rachel Winter: most relevant threads from our gender so again it wasn't specifically dedicated this white knight so we looked for threads within the subreddit that we're dedicated to the interactive fiction.

79
00:11:48.930 --> 00:11:58.980
Lauren Rouse (she/they): And so, when users would post about swipe nights on their tinder profile these two graphics on the left side of your screen are what it would show up looking like on their.

80
00:11:59.790 --> 00:12:05.400
Lauren Rouse (she/they): profile profile and where the choices were so in the top left, we have a bio.

81
00:12:05.970 --> 00:12:12.540
Lauren Rouse (she/they): which would just be if you open the tinder APP, and so it says that they had the ending of molly's House which is from the first episode.

82
00:12:12.930 --> 00:12:30.570
Lauren Rouse (she/they): And then the second image on the screen is a more in depth look in a bio and the bio actually says anyone else keep getting stressed out by the swype night game I keep selecting the wrong things, and they have a episode two with their ending and the choices that they made as well.

83
00:12:33.510 --> 00:12:42.240
Lauren Rouse (she/they): So after we collected our data from the are tender subreddit we used orange data visualization to run a sentiment analysis.

84
00:12:42.570 --> 00:12:49.920
Lauren Rouse (she/they): sentiment analysis uses natural language processing to determine whether text has a positive neutral or negative connotation.

85
00:12:50.670 --> 00:13:00.510
Lauren Rouse (she/they): Following sentiment analysis we create a heat map which is this image on your screen which orders, the data into blue negative emotions or yellow positive emotions.

86
00:13:00.780 --> 00:13:15.630
Lauren Rouse (she/they): There are also neutral responses which express neither positive nor negative responses sentiment analysis gets a lot of like flat kind of from academia about how you can't really tell if something is positive or negative.

87
00:13:15.990 --> 00:13:19.410
Lauren Rouse (she/they): And so that's why we wanted to compile also the neutral sentiments as well.

88
00:13:23.610 --> 00:13:32.640
Rachel Winter: So we actually found that there was a large amount of neutral statements, including those in which users were discussing their technical issues with the application.

89
00:13:32.880 --> 00:13:41.370
Rachel Winter: And then crowdsourcing potential troubleshooting solutions, so this provides us some insight into the role that platform, the coordinators and community.

90
00:13:41.850 --> 00:13:48.000
Rachel Winter: Have in the way that users interact so tender only enables private communication so it's a 14 says don't.

91
00:13:48.300 --> 00:13:57.270
Rachel Winter: enable crowd sourcing solutions which sends users in search of platforms with designs that better enable this type of communication such as read it with its dedicated subreddit.

92
00:13:58.200 --> 00:14:05.550
Rachel Winter: We also found that the compound score had an overall negative sentiment some users argued that white knight was annoying or useless.

93
00:14:05.850 --> 00:14:10.800
Rachel Winter: while others expressed frustration with the scenarios in the game, to which they cannot relate, such as the choice.

94
00:14:11.160 --> 00:14:17.730
Rachel Winter: Which required users to either cover for or expose a friend grams infidelity, which is the context for the quote.

95
00:14:18.030 --> 00:14:25.560
Rachel Winter: On the right hand side of the slide the girls will hate my choice because I covered for Graham but in all reality, I would have never gotten involved in the first place.

96
00:14:25.920 --> 00:14:32.100
Rachel Winter: So this indicates that although interactivity has commonly been associated with increased identification with characters.

97
00:14:32.430 --> 00:14:37.770
Rachel Winter: reactions to swipe might suggest that moral and ethical predicaments can result in an opposite reaction.

98
00:14:38.070 --> 00:14:47.670
Rachel Winter: Especially when user choices may result in an impact offline such as their potential matches matches on the tender platform and also potential future offline meetups.

99
00:14:48.210 --> 00:14:54.510
Rachel Winter: So this is just what the context of the tinder platform impacts user engagement with and response to the interactive fiction.

100
00:14:58.320 --> 00:15:11.010
Rachel Winter: So it not only highlighted the gamification in hyper textual methods at play in modern day dating but also brought to the forefront issues of morality and ethics inciting a potential partner, so the context of swype night on the to their platform.

101
00:15:12.390 --> 00:15:26.910
Rachel Winter: suggest that platform differences in Community impact audience reception of an engagement with fiction that's questions of morality, are more impactful in a story disengaged from us then from a story disengage from users online identities.

102
00:15:28.380 --> 00:15:32.850
Rachel Winter: Thank you, and we have our contact info here and I encourage you to read our paper to.

103
00:15:36.000 --> 00:15:49.830
Anna Nacher: Thank you so much, I guess, our perspective on what platform is changes from one presentation to another and actually that might be the running theme, or how we see the platforms through all the examples discussed here.

104
00:15:50.460 --> 00:15:51.660
Anna Nacher: Even if our next.

105
00:15:51.990 --> 00:15:58.710
Anna Nacher: Even though our next presentation is actually cross platform as alternate reality games usually are.

106
00:15:59.760 --> 00:16:00.450
justin.

107
00:16:02.850 --> 00:16:05.010
Justin: Oh yeah Thank you let me.

108
00:16:06.420 --> 00:16:07.590
Justin: Share screen.

109
00:16:13.770 --> 00:16:27.690
Justin: Okay hi everybody, my name is justin board neck, and my paper is called dangerous games our social media platforms and participatory propaganda, but we figured that out from the title on the slide but I figured I would just make sure.

110
00:16:29.880 --> 00:16:30.270
Justin: So.

111
00:16:31.740 --> 00:16:37.560
Justin: Before I give a brief overview of the specifics five minutes or so that were a lot and I wanted to first throughout some definitions.

112
00:16:37.830 --> 00:16:46.860
Justin: The first one is for alternate reality games, for those who aren't familiar for our purposes today i'll quote you a definition from the source of all human knowledge Wikipedia.

113
00:16:47.550 --> 00:16:57.660
Justin: Which is that an alternate reality game or arg is an interactive network to narrative that uses the real world as a platform and employees transmedia storytelling to deliver a story.

114
00:16:58.020 --> 00:17:08.040
Justin: That may be altered by players ideas or actions so we're going to use art for the rest of the session I professionally designed several arts for there's the definition there for video games and.

115
00:17:08.460 --> 00:17:12.540
Justin: marketing campaigns for films and private entertainment would work well with.

116
00:17:12.990 --> 00:17:22.380
Justin: When well executed they're really fun they're sort of like a massive live action role play with thousands of participants all working together to unravel the mystery or achieve a goal.

117
00:17:23.370 --> 00:17:30.660
Justin: So i'm guessing everyone knows it social media is I won't take the time to break that one down that will bring me to the third degree by title, which is participatory propaganda.

118
00:17:31.110 --> 00:17:37.140
Justin: This is a term coined by alicia wallace and Michael Burke, and represents a paradigm shift and propaganda distribution.

119
00:17:37.710 --> 00:17:48.780
Justin: Traditional propaganda comes from the top down, is the old ways it's usually run by the state or some other powerful body with the ability to widely produce and distributes the messaging.

120
00:17:49.350 --> 00:17:57.420
Justin: They do things like print newspapers and radio and television programming rewrite history books changing curriculum to get it to the masses.

121
00:17:57.960 --> 00:18:05.400
Justin: Under the new paradigm, though the propaganda is delivered from the ground up, so the original messaging is still produced by somebody with power agenda.

122
00:18:05.790 --> 00:18:12.210
Justin: But then it spread to a small group of hardcore true believers who then spread it through their own social channels.

123
00:18:12.540 --> 00:18:19.980
Justin: Both in person online, and you can see the potential for exponential growth here if there are 100 believers that you shared with 25 friends and family.

124
00:18:20.280 --> 00:18:33.330
Justin: and of those 25 say three by it and each Spencer 25 more friends and family well soon you've built your grassroots, in other words a top down effort transforms into a body bottom up, seemingly organic movement.

125
00:18:35.460 --> 00:18:43.560
Justin: So I have maybe to two minutes left out of five so at that time i'd like to briefly highlight a real world example which you're all probably familiar with, to some degree Q and.

126
00:18:44.250 --> 00:18:53.940
Justin: q.is the current conspiracy theory genre the United States, and though it's by no means the first example of sort of thing that I wrote about because he sought after 911 as well, for example.

127
00:18:54.780 --> 00:19:00.330
Justin: Briefly, for the blessedly out initiated but i'm sorry to do this to you q.is a conspiracy theory.

128
00:19:00.720 --> 00:19:10.200
Justin: That posits that the entire United States is controlled by a shadowy cabal of pedophiles and that the Members of this nefarious group are the leaders of the democratic party celebrities and billionaires.

129
00:19:10.680 --> 00:19:18.060
Justin: against these forces Donald trump is waging a war of justice and virtue, with the goals exposing their crimes and restoring America to its former greatness.

130
00:19:18.540 --> 00:19:22.890
Justin: There are a lot of reasons that people buy into this story and we don't have time to go through them in this talk, but.

131
00:19:23.370 --> 00:19:30.120
Justin: Many revolve around things like perceived as power bench and marginalization and alienation and, of course, if you believe this is true.

132
00:19:30.450 --> 00:19:36.840
Justin: You have a moral imperative to support the former President as loudly as possible and tell everybody, you know about what's going on, because children are at stake.

133
00:19:38.040 --> 00:19:43.140
Justin: Human on is a sort of alternate reality game and it's just that nobody has told the players that it is real.

134
00:19:43.530 --> 00:19:52.140
Justin: It exact exactly the same way as a game master the mysterious Hugh he's ostensibly a government official with first hand knowledge of trumps evaluate struggle.

135
00:19:52.440 --> 00:19:58.620
Justin: Q posts cryptic messages to social media which Q adherence rapid rapidly devour and parse for meaning.

136
00:19:59.130 --> 00:20:07.170
Justin: Just like players have an Arc spend hours poring over fictional websites and reading fabricated documents as they attempt to solve puzzles which are created by the end designers.

137
00:20:07.410 --> 00:20:13.650
Justin: Q followers do the same thing with real life, the smallest things become imbued with utmost important so, for example.

138
00:20:13.860 --> 00:20:25.560
Justin: At trump's with farewell speech on January 21 there were 17 American flags on stage, he was the 17th letter of the alphabet So this was clearly at coded sign to keep the faith, despite Joe biden's and petting a dog duration.

139
00:20:26.730 --> 00:20:34.080
Justin: This is all quite terrifying to people like me who designed this sort of entertainment as we're seeing our work co opted for decidedly the various purposes.

140
00:20:34.530 --> 00:20:41.340
Justin: Unfortunately, many game designers aren't even aware that their tools are being appropriated level load what those tools are being made to do.

141
00:20:41.940 --> 00:20:47.640
Justin: There are a few ways to go about trying to address this problem and i'd be happy to talk about them in the Q amp a discussion if folks are interested.

142
00:20:48.180 --> 00:20:55.410
Justin: But the big picture is that we have a real problem here, and currently the commercial games industry is perfectly happy to keep pressing forward and happy ignorance churning out.

143
00:20:55.740 --> 00:21:06.090
Justin: Ever more entertained but that bolsters rather than undermines those who have real interested subverting democracy i'm sorry to end on that downer note and it's not all bad I promise but we're uh.

144
00:21:06.690 --> 00:21:14.640
Justin: we're about at the end of the five minutes that they told us to use, so I wanted to turn it over to the back back to the moderator for the Q amp a here from the other panelists as well i'm sure we could.

145
00:21:15.090 --> 00:21:20.640
Justin: loop discussion back around to some of these things if the opportunity arises like you very much.

146
00:21:22.080 --> 00:21:23.400
Anna Nacher: Thank you very much, I.

147
00:21:24.570 --> 00:21:45.180
Anna Nacher: I on the other hand, encourage the audience, to have a peek at the papers which are stored in a conference system it's definitely interesting right and and now the Q amp a session we have plenty of time and I hope we have lots of interesting questions on.

148
00:21:46.350 --> 00:22:01.920
Anna Nacher: That the one is already here, actually, two of them are already here in the chat one comes from alan's on time and then one from Germany hide and I didn't know and would you like to pose the question now yourself.

149
00:22:05.040 --> 00:22:05.880
Alan Sondheim: Can you hear me.

150
00:22:06.360 --> 00:22:17.550
Alan Sondheim: yeah yeah I was reading Gordon all ports book on studies and prejudice and one of the things that he talks about as an experiment was done.

151
00:22:18.060 --> 00:22:32.700
Alan Sondheim: This is all really I think back in the 50s where a group of individuals who are class somewhere classified as prejudice, some are classified as non prejudice in relationship to say black issues and so forth, and they were showed.

152
00:22:33.810 --> 00:22:50.520
Alan Sondheim: Both groups everybody was shown a truncated a diagram of a truncated pyramid pyramid which was tilted to one side and the people, and then they were asked several months later to redraw to draw with a remember to the pyramid and the people who were prejudiced.

153
00:22:52.020 --> 00:23:02.010
Alan Sondheim: By and large, through the pyramid symmetrically which it wasn't in the original drawing in people who didn't score high on the prejudice scale do it as closer to the original which was.

154
00:23:02.460 --> 00:23:14.520
Alan Sondheim: lopsided so there's a they were making a point as a tendency to simplify and to find these causal change the symmetries which are related to causal change.

155
00:23:16.320 --> 00:23:28.050
Alan Sondheim: Rather than deal with the complexity of, say, the contemporary world which cumin on cuts through brilliantly actually because if you can trace everything to something that's on the level of mythos.

156
00:23:28.590 --> 00:23:39.630
Alan Sondheim: becomes much easier to believe, because then everything becomes a sign or signifier towards that, so I think this plays very much into what we're on to what we're talking about here.

157
00:23:44.550 --> 00:23:48.660
Anna Nacher: This is a question for someone particular all to all panelists.

158
00:23:49.800 --> 00:23:51.930
Alan Sondheim: So pamela is particularly to the last.

159
00:23:52.500 --> 00:23:53.520
Anna Nacher: Thanks Jackson yeah.

160
00:23:53.580 --> 00:23:54.750
justin so maybe yes.

161
00:23:55.830 --> 00:24:00.990
Justin: i'm not sure I understood understood the question, could you could you be.

162
00:24:02.040 --> 00:24:06.060
Justin: repeat the core of it, just like you said a lot of stuff so I want to make sure I understand.

163
00:24:06.240 --> 00:24:28.650
Alan Sondheim: It was more it was more a comment on where prejudice arrives arises where Q and on arises needs situation and basically it's the idea that you collapse, the complexity of contemporary life into into simply a core, which is a core based on classical cause and effect so.

164
00:24:28.680 --> 00:24:30.450
Alan Sondheim: Yes, a comment about this.

165
00:24:30.900 --> 00:24:32.130
Justin: yeah I think you're right here to.

166
00:24:32.130 --> 00:24:40.620
Alan Sondheim: live, particularly if you're not particularly educated or if you're not used to really questioning critique or developing critique of your own.

167
00:24:41.910 --> 00:24:42.090
Justin: yeah.

168
00:24:42.150 --> 00:24:43.200
Justin: I think you're right about.

169
00:24:48.960 --> 00:24:55.230
Justin: What you said it's about collapsing complexity that's that's one of those reasons that I mentioned.

170
00:24:56.610 --> 00:25:05.550
Justin: people get addicted is because they feel like the World doesn't make sense and here's the explanation that says Oh, you know here's a very straightforward reason why.

171
00:25:06.030 --> 00:25:14.190
Justin: All of the things that seemed to make sense in your life before don't anymore it's just do this, that everything will be fine the gap.

172
00:25:16.050 --> 00:25:27.030
Justin: And so it simplifies like you said, a world that appears to be nonsensical into a framework that they could easily follow.

173
00:25:28.620 --> 00:25:36.660
Alan Sondheim: But it's interesting that it also, at least according to that one experiment and i've seen other things similar it also really affects your ability.

174
00:25:37.020 --> 00:25:48.900
Alan Sondheim: Later on, to process information with it pyramids people actually remembered things differently, as a result of something as a result of a kind of compression of belief.

175
00:25:51.180 --> 00:25:57.360
Anna Nacher: yeah Thank you justin would you like to to answer to this as well, our other panelists.

176
00:25:58.320 --> 00:25:59.820
Justin: Have any things that the other.

177
00:26:00.600 --> 00:26:05.670
Anna Nacher: Other panelists will do you like to comment on what just what was just said.

178
00:26:10.980 --> 00:26:20.250
Anna Nacher: yeah, so I think yeah Thank you Thank you and I actually it is a very complex issue, so I don't think this panel alone would you know ever.

179
00:26:21.270 --> 00:26:25.230
Anna Nacher: Ever fulfill the whole space that's needed to discuss.

180
00:26:26.340 --> 00:26:27.750
Anna Nacher: The subject.

181
00:26:28.920 --> 00:26:30.570
Anna Nacher: So I like to.

182
00:26:32.940 --> 00:26:38.970
Anna Nacher: i'd like to turn to Jeremy and you'd like to ask your question yourself.

183
00:26:40.290 --> 00:26:40.770
Jeremy Hight: um.

184
00:26:42.660 --> 00:26:51.810
Jeremy Hight: i've been a fan of ben's project for a while and it was really, really fascinating to see to other projects that to me i'm seeing all these connective threads.

185
00:26:52.410 --> 00:27:07.200
Jeremy Hight: And one of them is that I teach at two colleges and one of them is done, but the other I teach ethics and rhetoric and to have the options that we've been covering throughout the Semester are that the kind of the the.

186
00:27:08.370 --> 00:27:11.070
Jeremy Hight: trend of that sort of fracture line between techno.

187
00:27:11.070 --> 00:27:12.240
Jeremy Hight: utopianism.

188
00:27:12.540 --> 00:27:23.790
Jeremy Hight: And dystopia and the immersive kind of narcotizing nature of so much information, and so you have tinder which you can passively scroll through or you can engage relationships.

189
00:27:24.240 --> 00:27:31.350
Jeremy Hight: You have conspiracy theories which had been rising, and some of the some of the things we looked at her some people argue it's.

190
00:27:31.710 --> 00:27:37.560
Jeremy Hight: The dystopia times, or any other say perhaps it's people looking at in terms of psychology that.

191
00:27:38.310 --> 00:27:48.900
Jeremy Hight: When the world is so uncertain conspiracy theories are like a warm cup of cocoa, because you can find an answer to something you can understand, like the early naming of gods in history right.

192
00:27:49.710 --> 00:27:57.840
Jeremy Hight: And then ben's project is how, and I know him through social media, so this is perfect, to start with, that is, that.

193
00:27:58.320 --> 00:28:13.200
Jeremy Hight: You can passively scroll through your social media but it's been so dark for at least two years now that it becomes a dooms girl so he's touching on something, but the thread that I that I was curious among all the panelists is that.

194
00:28:14.430 --> 00:28:20.220
Jeremy Hight: What do you think about what what someone like me sitting here at 7am whatever here in La.

195
00:28:21.210 --> 00:28:26.430
Jeremy Hight: That i'm seeing between all what you're dealing with is that so there's a narrative within tinder tinder.

196
00:28:26.730 --> 00:28:36.180
Jeremy Hight: and its promotional but it's fascinating that you're looking at data that was kind of like the normal set data, like the mundane any data, not just the expected engagement.

197
00:28:36.570 --> 00:28:49.710
Jeremy Hight: That the commercial aspect would go for and how that relates to the larger platform and then ben's project and then justin's like How much is it that you're all incisively going deeper into things that we can passively just.

198
00:28:50.790 --> 00:28:52.500
Jeremy Hight: Be immersed in on our phones.

199
00:28:55.170 --> 00:28:55.620
Anna Nacher: Thank you.

200
00:28:56.340 --> 00:28:56.850
Sir.

201
00:28:58.230 --> 00:28:58.560
Anna Nacher: Ben.

202
00:28:58.620 --> 00:28:59.370
Anna Nacher: Would you like to.

203
00:28:59.820 --> 00:29:02.850
Ben Grosser: comment sure yeah thanks JEREMY.

204
00:29:04.650 --> 00:29:06.810
Ben Grosser: For that yeah that's an interesting.

205
00:29:07.830 --> 00:29:18.330
Ben Grosser: yeah I think I think I appreciate your efforts to draw connections across these different papers, I guess you know playing off of a little bit.

206
00:29:19.740 --> 00:29:26.610
Ben Grosser: Is the idea, and then the theme of the conference just platform platform in the pandemic, I suppose, and while.

207
00:29:27.240 --> 00:29:38.640
Ben Grosser: You know, in my case, social media in general, maybe is the platform i'm thinking about and for Rachel and lauren it's it's tender for justin I suppose it's it's more broad than that but, of course.

208
00:29:39.630 --> 00:29:50.910
Ben Grosser: Maybe eight channel the case that Q and on is the platform, but it's not quite the same thing, but definitely behind the scenes of all platforms is the design of the algorithm that.

209
00:29:51.900 --> 00:30:02.520
Ben Grosser: presents information with an intention and that intention is not always in the foreground I would say, and I see that as maybe a.

210
00:30:03.270 --> 00:30:13.710
Ben Grosser: connective tissue across the papers in response to to JEREMY that in the case of social media it's feed algorithms designed to engage in the case of tinder.

211
00:30:14.250 --> 00:30:24.540
Ben Grosser: You know, obviously there's the intention to connect and enable connection, but of course there's also the gathering of data and everything else that happens in every kind of platform.

212
00:30:25.410 --> 00:30:35.370
Ben Grosser: algorithmic platform and the case of Q and on perhaps Q and on, I suppose, might be considered the the algorithm behind the scenes that instigates and triggers.

213
00:30:36.900 --> 00:30:41.910
Ben Grosser: different kinds of reactions, but of course there's, the environment, maybe it's the environment of kind of.

214
00:30:44.040 --> 00:30:54.570
Ben Grosser: conspiracy theory thinking that becomes the algorithm in that case anyway that's that's just one way I kind of response I can see some connections.

215
00:30:55.740 --> 00:31:06.090
Anna Nacher: Thank you Ben and lauren lauren and Rachel I have also some separate questions for you, about tinder in a moment, but would you like to.

216
00:31:07.890 --> 00:31:10.350
Anna Nacher: comment on on this question.

217
00:31:11.490 --> 00:31:18.630
Rachel Winter: yeah I think that a lot of the time, the sort of activity that we see as being sort of passive scrolling is actually.

218
00:31:19.080 --> 00:31:24.660
Rachel Winter: A lot more meaningful than we perceive in addition to the algorithms like Ben was mentioning.

219
00:31:25.110 --> 00:31:32.190
Rachel Winter: The design of platforms, I mean platforms are designed by human beings and then they're instantiated with the values of those human beings.

220
00:31:32.490 --> 00:31:42.180
Rachel Winter: And they shaped the way that people engage with both the technological acquaintances and the Community on those platforms and I think that understanding how.

221
00:31:42.690 --> 00:31:51.180
Rachel Winter: actually very intentional, a lot of our seemingly meaningless activity is can give you are really significant look into not only platform design.

222
00:31:51.480 --> 00:32:00.900
Rachel Winter: but also how people approach those designs so whether or not people choose to use the importance visible in the way that they're intended or choose to resist that intention.

223
00:32:01.410 --> 00:32:11.760
Rachel Winter: Their choices are still being shaped by the performances of these platforms and I think that understanding that and understanding how people engage differently with different platforms and different populations.

224
00:32:12.240 --> 00:32:24.330
Rachel Winter: and give us a pretty significant insight not only into it the human activity factor of it, but also how the design can impact those choices.

225
00:32:25.980 --> 00:32:26.160
You.

226
00:32:31.110 --> 00:32:31.530
Anna Nacher: lauren.

227
00:32:33.600 --> 00:32:35.250
Anna Nacher: Just yeah so.

228
00:32:35.310 --> 00:32:37.140
Lauren Rouse (she/they): No, I think Rachel said everything but.

229
00:32:37.140 --> 00:32:37.770
Lauren Rouse (she/they): I was.

230
00:32:39.180 --> 00:32:46.710
Anna Nacher: sort of waiting for free also commenting on but anyway, like I said, there is another question directed at you specifically.

231
00:32:47.550 --> 00:32:54.630
Anna Nacher: We have a monitoring chance, by the way, but if you want to ask your question or cervical also raise hands and I be.

232
00:32:55.050 --> 00:33:08.280
Anna Nacher: dividing my my attention between two channels and we have two questions from manual Cox actually one question is for justin and another one is for lauren and Rachel and then soren bold so Daniel please.

233
00:33:09.330 --> 00:33:11.850
Anna Nacher: Would you like to ask your question yourself.

234
00:33:14.040 --> 00:33:16.140
Anna Nacher: or just direct people to chat.

235
00:33:17.880 --> 00:33:19.950
Daniel Cox: Yes, I could attempt to answer it or ask it sorry.

236
00:33:20.250 --> 00:33:27.840
Daniel Cox: i'm just I feel like this was actually answered before but i'm interested within the art design spaces, could you talk a little bit more about the complications.

237
00:33:28.080 --> 00:33:38.700
Daniel Cox: When our design spaces come into contact with conspiracy theories, I feel like you started to address that and i'm interested in if there are any interesting stories or comments you could just share on that topic.

238
00:33:40.110 --> 00:33:47.370
Justin: So you mean when our spaces come into contact with like real conspiracy theories that are out there in the world, independent of the game.

239
00:33:47.850 --> 00:33:48.300
Correct.

240
00:33:49.350 --> 00:33:54.570
Justin: yeah well I think it's very common for that to happen.

241
00:33:55.890 --> 00:34:05.850
Justin: Because I tell you that one of the ready made forums for an alternate reality games if you're a designer and you just want to make one is a conspiracy theory narrow down.

242
00:34:08.160 --> 00:34:14.910
Justin: Because it just presented it, you can make up anything and you could just say oh yeah it's part of the conspiracy and people buy into it right.

243
00:34:15.960 --> 00:34:16.560
Justin: fictional it.

244
00:34:19.530 --> 00:34:37.530
Justin: I haven't seen a lot of contact with people who are currently playing an alternate reality game butting up against a real conspiracy theory that is not part of the game and having that ended up becoming incorporated.

245
00:34:39.060 --> 00:34:48.870
Justin: that's one of the strengths of the farm is that they cast a very wide net and then examine everything so they might say hey there's this thing going on is this part of the game.

246
00:34:49.620 --> 00:34:57.900
Justin: That does investigate and say like maybe probably not you know, put it on the list of things that like to monitor, but we can't get anything out of it.

247
00:34:59.700 --> 00:35:12.030
Justin: it's at this is especially in every really successful game with thousands of players, like a ruthlessly efficient to plot efficient process of vetting content so.

248
00:35:13.200 --> 00:35:23.790
Justin: i'm not sure that i've seen existing conspiracies get co opted into a game, but I have seen.

249
00:35:24.660 --> 00:35:38.850
Justin: conspiracy theories that people actually believe in in the real world, like the illuminati or the Committee of 300 or the protocols of the elders of Zion that sort of stuff used as the basis to make a fictional if that makes sense.

250
00:35:41.700 --> 00:35:42.150
Anna Nacher: Thank you.

251
00:35:42.630 --> 00:35:43.860
Anna Nacher: I agree it is very.

252
00:35:43.860 --> 00:35:59.820
Anna Nacher: interesting topic, so to speak, like you know the alternate reality game, I mean customer conspiracy theorists might have prepared the ground for you know some kind of fantasy reality play and Daniel your second question is for lauren and Rachel right.

253
00:36:00.810 --> 00:36:12.000
Daniel Cox: Yes, Lord and Rachel i'm interested in so Rachel was speaking to the forces of different platforms i'm interested in how important secondary platforms, you mentioned reddit in connection to tender.

254
00:36:12.750 --> 00:36:23.190
Daniel Cox: How much do these create an opportunity or create a space for communities from other platforms, so if your example you mentioned collecting things from reddit and i'm kind of interested in.

255
00:36:23.700 --> 00:36:38.790
Daniel Cox: The offenses of different platforms and the ways in which, if you want to sort of speak to the content from your paper connecting allowing Twitter users to congregate on another platform to talk about a different platform, this is interesting sort of inter platform connection here.

256
00:36:40.590 --> 00:36:51.810
Lauren Rouse (she/they): yeah definitely so um we initially did this research, and I think the beginning of 2020 and because it was just about like three months after the original.

257
00:36:52.560 --> 00:37:05.460
Lauren Rouse (she/they): swipe night had aired and so we really wanted to see kind of what people were talking about on other platforms and when we had gone on to Twitter we couldn't really find anything super specific so we decided to.

258
00:37:05.700 --> 00:37:16.110
Lauren Rouse (she/they): head over to read it, where there is a pretty big tinder community and people use that platform to like share funny bios or profiles that they find.

259
00:37:16.860 --> 00:37:28.740
Lauren Rouse (she/they): They do like a match of the week thing, where people will share like they're beginning messages with a match, and they, like all vote on it and they talking about like they're bad experiences, or just people being like rude on tinder.

260
00:37:29.340 --> 00:37:41.220
Lauren Rouse (she/they): But it definitely had like kind of the tech support like aspect of it that we hadn't expected when originally setting out force white knight specifically and.

261
00:37:41.820 --> 00:37:51.720
Lauren Rouse (she/they): So there are definitely like a lot of ordinances for looking at these like trans platform type uses for something like swipe my it, because it shows that.

262
00:37:52.140 --> 00:38:00.540
Lauren Rouse (she/they): tinder which is specifically often like very personal and you usually don't get to share that kind of aspect with your matches on tinder.

263
00:38:00.780 --> 00:38:12.060
Lauren Rouse (she/they): It shows that that still build like a community of users outside of maybe like your close friends or anything like that so looking trans platform, why is, we were able to see that there were.

264
00:38:12.780 --> 00:38:19.560
Lauren Rouse (she/they): Definitely places that people like congregate and talk about tinder that are not just on listener APP as well.

265
00:38:21.300 --> 00:38:22.350
Lauren Rouse (she/they): Rachel do you have anything that.

266
00:38:24.360 --> 00:38:24.720
Anna Nacher: Thank you.

267
00:38:25.380 --> 00:38:25.650
Lauren Rouse (she/they): Thank you.

268
00:38:26.280 --> 00:38:36.150
Anna Nacher: More questions coming to you, but now i'm passing the torch to surrender, who has who has another two questions, one for Jesse and one for Ben.

269
00:38:37.350 --> 00:38:40.440
S?ren Bro Pold (he, him): yeah or maybe it's a question for both of you.

270
00:38:42.690 --> 00:38:43.530
S?ren Bro Pold (he, him): I was, I was.

271
00:38:44.820 --> 00:39:00.960
S?ren Bro Pold (he, him): Of course dropped by what been talked about when he sort of talked about this minimalist hiding that you try to contact with a minimalist revealing and and you ended with this that the end of June scrolling is the is endless doing scrolling.

272
00:39:02.940 --> 00:39:09.360
S?ren Bro Pold (he, him): And and and then we have this example of the sixth of January interaction with Q and on.

273
00:39:10.110 --> 00:39:19.470
S?ren Bro Pold (he, him): And I just you know i'm i'm not American side you know I didn't follow it that kills you but, but of course we all heard about it, and one of the things that.

274
00:39:19.890 --> 00:39:33.840
S?ren Bro Pold (he, him): struck me was the way, many of these people that were caught in Congress were surprised somehow that it wasn't a game, or that it was something that was really happening.

275
00:39:34.500 --> 00:39:51.120
S?ren Bro Pold (he, him): And not you know just something on social media, but something that had real consequences and was actually you know illegal and stuff so, so in that sense, it seems to become some kind of example of an it is ization of politics.

276
00:39:52.230 --> 00:39:55.260
S?ren Bro Pold (he, him): That happens through these are great new platforms.

277
00:39:58.680 --> 00:40:05.100
S?ren Bro Pold (he, him): That they were they are a word coding, but we all caught in them somehow.

278
00:40:06.720 --> 00:40:13.830
S?ren Bro Pold (he, him): And and and and so i'm i'm wondering, and you know it's a it's a reflection of gone with for a while and.

279
00:40:14.430 --> 00:40:21.270
S?ren Bro Pold (he, him): Also talk to Ben with it earlier but but, but how can we ever start to understand read this this way of.

280
00:40:22.170 --> 00:40:32.070
S?ren Bro Pold (he, him): You know reading how they read us in some sense of course it's Bernard but in other ways it's also highly complex and maybe as complex as the many ways these platforms.

281
00:40:32.640 --> 00:40:49.020
S?ren Bro Pold (he, him): Try to hide it so it's yeah so it's both a political question but it's also very sort of an infrastructural interface interface question right and maybe maybe the political question is for justin and the more interface related could be for been.

282
00:40:52.920 --> 00:40:55.290
Ben Grosser: yeah thanks or and certainly.

283
00:40:57.900 --> 00:41:01.440
Ben Grosser: I guess I think about the political part of it, too, but the the.

284
00:41:03.570 --> 00:41:13.590
Ben Grosser: Certainly in the way I ended up writing about the work unless doom scroller was inspired by your work and Christians work to just try to think about.

285
00:41:15.960 --> 00:41:22.080
Ben Grosser: We all intern I mean I think when we we live in algorithmic platforms that are.

286
00:41:23.490 --> 00:41:29.160
Ben Grosser: In whether it's all the social media platforms are making decisions about what we see and what we don't all the time.

287
00:41:30.840 --> 00:41:45.960
Ben Grosser: I think a condition that's common across most if not all users of algorithmic platforms is some kind of internalization to internalized idea of what the algorithm is or what it's doing or how it thinks or.

288
00:41:47.100 --> 00:42:01.830
Ben Grosser: Usually manifest in the kinds of signals that people send back to the system, imagining that it's going to have some positive effect they might like certain kinds of things, thinking that will produce more of those things that they might.

289
00:42:03.270 --> 00:42:11.250
Ben Grosser: move quickly past other things, and hopes that the system doesn't lock on to that and show them more of the thing they don't want.

290
00:42:12.600 --> 00:42:23.010
Ben Grosser: But often when you talk to at least I think about my own teaching with students at the University, you know we talked about social media and there's a.

291
00:42:23.790 --> 00:42:38.610
Ben Grosser: there's often a kind of dismissive attitude towards the you know, lack of worry, a lack of concern that kind of is present about all this decision making and what its effects might be and.

292
00:42:40.260 --> 00:42:41.430
Ben Grosser: I think you know the.

293
00:42:42.630 --> 00:42:52.620
Ben Grosser: With thinking about the Meta interface and minimalist hiding this kind of you know super slick make it all really clean and Nice and then, like all of the massive.

294
00:42:54.270 --> 00:43:03.000
Ben Grosser: distributed server based surveillance systems that are going on underneath capturing every possible move I talked about this in detail in the paper, but you know recording.

295
00:43:03.540 --> 00:43:10.140
Ben Grosser: Every scroll every every moment you hold your mouse over something but don't click everything you type, but then delete.

296
00:43:10.470 --> 00:43:21.480
Ben Grosser: It just let you know every little bit is captured and recorded and analyze in order to best engage the user to keep them on the platform and so.

297
00:43:22.380 --> 00:43:34.620
Ben Grosser: part of what I found and reactions to the endless doom scroller which is really not a social media platform it's kind of just taking the interface conventions and the message conventions of of headlines and putting into.

298
00:43:35.730 --> 00:43:48.390
Ben Grosser: A very simplified form is that it often would produce this reaction of Oh, this is what i've been doing with my time i've just been.

299
00:43:49.290 --> 00:43:56.250
Ben Grosser: stuck in this system, and when you when you boil it down it's easier to see it's easier to feel.

300
00:43:56.550 --> 00:44:08.910
Ben Grosser: That that's what we've been feeling I think that's kind of what I end up hearing from people and so that's where I kind of decided to think about it, as this minimalist revealing and, as a kind of a counter to the minimalist hiding that.

301
00:44:11.220 --> 00:44:16.860
Ben Grosser: Your minimalist hiding, you know I would think of is as a strategy to.

302
00:44:18.180 --> 00:44:30.900
Ben Grosser: push you know completely off the screen the things that they don't want you to know and with middle most revealing I guess i've been thinking about it is pushing only the things onto the screen that I want people to think about.

303
00:44:32.190 --> 00:44:48.660
Ben Grosser: As in the ways that they engage with interface, so you know getting rid of the thing that that maybe drew them there in the first place, but leaving the things that the system gives them as the primary ordinances, which in this case or bad news headlines and scroll forever.

304
00:44:50.160 --> 00:44:51.960
Anna Nacher: Thank you so much, and justin.

305
00:44:53.040 --> 00:44:53.490
Justin: yeah.

306
00:44:54.780 --> 00:45:01.980
Justin: And I think this answer might address some of the questions that have popped up in chat since that I see there's a q&a discussion going on there.

307
00:45:04.050 --> 00:45:14.520
Justin: And I think the first part is to adjust you know you say you're not American you did you you're aware of it, but you weren't paying attention, and I think for people who live in America.

308
00:45:15.660 --> 00:45:17.190
Justin: Most of them are not aware of this but.

309
00:45:18.840 --> 00:45:30.390
Justin: conspiracy theory Q amp out is not is the latest incarnation in a long line they said, you know we saw the same sort of thing after September 11 but even going further back to that to like.

310
00:45:31.710 --> 00:45:49.920
Justin: The election of Andrew Jackson we saw conspiracy theories as the primary or amongst the primary political toolboxes for getting elected to the Presidency, even though it's probably no coincidence that Donald trump says Jackson was his favorite President.

311
00:45:52.500 --> 00:46:07.770
Justin: And the reemergence of conspiracy theories into the political sphere, if the 21st century is actually I think part of a larger like reversion to the mean for American culture.

312
00:46:09.330 --> 00:46:20.880
Justin: That polarization the misinformation the fake news the conspiracy theories all of that used to be very tightly wound into the American political culture.

313
00:46:21.360 --> 00:46:29.790
Justin: And it sort of vanished after the post war period for reasons that I could speculate about i'm not an expert, I think it has to do with shared experiences.

314
00:46:30.090 --> 00:46:45.240
Justin: kabaddi racial gender sexuality amongst those who are in power, allowing them to sort of have a common ground, which is harder today with increase representation and rights, which I think is a good thing, but it's introduced new challenges.

315
00:46:48.180 --> 00:47:04.830
Justin: So I think that the platform concerned in conspiracy theory when it comes to Q and on is that it lets it spread much more efficiently right, you know if you let's say in 1960 if you believed that.

316
00:47:05.850 --> 00:47:20.010
Justin: I don't know aliens were going to arrive and peach universal brotherhood which was you know we all think that you know if you look at alien narratives from the 16th that's what was that was a universal brotherhood and harmony and understanding, all our age of aquarius stuff.

317
00:47:22.440 --> 00:47:28.860
Justin: Even if some people believed you you'd have to like go out and personally tell people about this at the vast majority, people are gonna say to you.

318
00:47:29.040 --> 00:47:39.300
Justin: hey you're crazy and, like the group pressure around that it's going to make it to the you're not going to get very far, but these platforms, allow us to find very specialized niche audiences to reach.

319
00:47:40.950 --> 00:47:47.550
Justin: That you would never be able to find out, it allows your global reach as well, which is obviously these conspiracy theories cropping about other cultures as well.

320
00:47:48.720 --> 00:47:52.770
Justin: I don't know that sort of adjust what your question was in a major way.

321
00:47:55.260 --> 00:47:56.970
S?ren Bro Pold (he, him): yeah yeah yeah definitely.

322
00:47:58.470 --> 00:48:09.390
S?ren Bro Pold (he, him): It is this kind of if this if this station that we are your to talk about different ways of propaganda, you know if it's quite willing to do that, I guess.

323
00:48:10.050 --> 00:48:22.650
Anna Nacher: yeah and there's a larger background, so to speak, to those articles background i'm thinking about reaction is movement dark enlightenment, you know those obscure philosophers such as email us at Loyola or.

324
00:48:23.550 --> 00:48:32.550
Anna Nacher: Or, I extend their blogging Even so, we could discuss it, I think, for the next and our to see interesting coincidence yeah justin.

325
00:48:32.880 --> 00:48:36.570
Justin: yeah I have a question for Ben actually that I want to ask them.

326
00:48:38.910 --> 00:48:41.250
Justin: that crops up while I was reading his paper so.

327
00:48:42.690 --> 00:48:43.410
Justin: This.

328
00:48:45.090 --> 00:48:51.930
Justin: I don't want this to feel like a depict, but it may be really curious, so I hope you have an answer for me, but it's about the psychology of scrolling.

329
00:48:53.820 --> 00:49:05.580
Justin: So I was thinking of it right at the top, where you talked about doing this crawlies this new compulsive behavior right, so I wanted to ask is this, is this really a new behavior because I was thinking about.

330
00:49:07.020 --> 00:49:11.190
Justin: Oliver Wendell Holmes senior not not the Supreme Court justice, this is father.

331
00:49:12.510 --> 00:49:18.450
Justin: He wrote that I know this is the electronic literature foundation, but bear with me, this is about newspapers.

332
00:49:20.220 --> 00:49:26.580
Justin: You wrote about the newspaper habit in 1861 in the Atlantic, you read about how this sort of perpetual.

333
00:49:27.030 --> 00:49:31.560
Justin: Inter inter communication, which was joined to the power of instantaneous action.

334
00:49:31.950 --> 00:49:38.400
Justin: keeps us alive with excitement there's, not a single bullet to that comes best what we're about to do.

335
00:49:38.700 --> 00:49:44.970
Justin: For a week of Sub great engagement it doesn't matter if it's true or false every hour early power graphs are laden with.

336
00:49:45.270 --> 00:49:55.620
Justin: You know, information and he concludes by saying that, like only the bread and the newspaper the things that we have to have right everything else we could do without as a society and, of course.

337
00:49:56.160 --> 00:50:04.770
Justin: You know 1861 this coincided with another event like the pandemic that induced massive social upheaval at anxiety, which was the civil war.

338
00:50:06.270 --> 00:50:26.160
Justin: So i'm wondering like what we're calling doom scrolling today could be possibly a manifestation of something more deeper that arises in human psychology whenever there's not enough information about something that's particularly Titanic, the culture and the throes of solitude uncertainty.

339
00:50:27.750 --> 00:50:34.230
Justin: And I you know you acknowledge that the endless scroll is like vastly more addicting these platform holders like complicit in a lot of.

340
00:50:34.650 --> 00:50:44.100
Justin: horrible things that I don't want to discount that but I wonder how much of this would be occurring, even without the algorithms like are we just programmed to do the scroll at the end, regardless of the error.

341
00:50:46.080 --> 00:50:48.030
Ben Grosser: yeah thanks for that testing.

342
00:50:50.910 --> 00:51:01.620
Ben Grosser: So a couple a couple of responses that I would I would give one is that and I, and I do go into some of this history of the paper didn't have time in the talk, but.

343
00:51:02.370 --> 00:51:10.230
Ben Grosser: Is we it's been well studied that we have a predisposition a psychological predisposition to the negative that.

344
00:51:10.980 --> 00:51:25.050
Ben Grosser: I mean, this is what headline writers for all of time have been playing on is that a certain quality of negative in a headline grabs our attention more so than a happy positive one.

345
00:51:26.160 --> 00:51:27.720
Ben Grosser: I quoted in the paper.

346
00:51:28.770 --> 00:51:35.220
Ben Grosser: You know if it bleeds it leads is the is the phrase that you hear in the news that emerged in the 80s.

347
00:51:36.300 --> 00:51:45.450
Ben Grosser: You know that anything negative is going to grab me, and this has been looked at in network news and basically any kind of news space, but.

348
00:51:47.190 --> 00:51:51.090
Ben Grosser: When I think about doom scrolling in the current era it's.

349
00:51:53.640 --> 00:51:59.250
Ben Grosser: it's more than a predisposition to the negative because.

350
00:52:00.660 --> 00:52:13.800
Ben Grosser: In the case of a newspaper it's a finite object per day with a finite list of options in an order that was pre determined, but is fixed for all users.

351
00:52:15.570 --> 00:52:24.900
Ben Grosser: Not everybody gets a custom newspaper perfectly designed to keep them focused on the paper they get the paper and.

352
00:52:25.650 --> 00:52:42.900
Ben Grosser: They get to play with it, but in the cases of social media platforms it's not just that the content on the social media platform in the pandemic was perhaps the most activating for someone who is predisposed to the negative because it was global crisis.

353
00:52:45.030 --> 00:52:56.160
Ben Grosser: existential uncertainty, you know threats to health, etc, but these were platforms that were watching every move that we make as a user.

354
00:52:56.880 --> 00:53:12.900
Ben Grosser: Using that analysis to give us precisely the right bad news headline next such that that one keeps us scrolling down to the next one, and to the next one, etc Wendy I quote Wendy China.

355
00:53:13.470 --> 00:53:26.550
Ben Grosser: In the paper to who talks about the way that social media platforms produce neoliberal subjects who are always find always searching never finding it puts us into these kinds of loops.

356
00:53:26.880 --> 00:53:43.170
Ben Grosser: Even in that talking in the paper about how we get turned almost transformed into a while loop thinking computationally where the STOP condition is when there's no more to read or when we're no longer anxious and.

357
00:53:44.250 --> 00:53:55.950
Ben Grosser: infinite scroll ensures there's always something more to read and profiling algorithmic profiling of the user in in the case of global pandemic or a case of global uncertainty.

358
00:53:57.240 --> 00:53:57.870
Ben Grosser: Is.

359
00:53:59.040 --> 00:54:06.930
Ben Grosser: ensures that will always be anxious it's like keeping the anxiety level up high enough that it just makes it very hard to as.

360
00:54:07.980 --> 00:54:09.750
Ben Grosser: Garrett loving says.

361
00:54:10.830 --> 00:54:17.580
Ben Grosser: describe your camera the exact quote but basically makes it really hard to disconnect from the system to disrupt our own behavior, I think, is how he puts it.

362
00:54:18.840 --> 00:54:23.370
Ben Grosser: So anyway that's those wasn't taught so does it mean to me that quality is.

363
00:54:24.870 --> 00:54:34.560
Ben Grosser: Is a dramatic escalation of of the CES of this what we might call doom scrolling and the previous era before algorithmic feeds.

364
00:54:35.580 --> 00:54:39.000
Anna Nacher: yeah Thank you so much um I think political and.

365
00:54:39.360 --> 00:54:47.100
Anna Nacher: political environment and the epidemic actually the pandemic creates the environment where it happens and i'm reminded by Mark sample.

366
00:54:47.340 --> 00:55:00.570
Anna Nacher: commented in chat that for him and the zoom scrolling started November 2016 and I think we all have local political moments when one does and Islam scholar happened, also in Europe in the country where i'm based to.

367
00:55:01.200 --> 00:55:14.550
Anna Nacher: But we still have three questions, I would like to accommodate one from devin who is kind of a general question and the one from Magdalena and yet another one from Christian, so I hope we have enough time 20 minutes, so it should be.

368
00:55:15.180 --> 00:55:25.050
Anna Nacher: Okay, to accommodate the three question mentioned that in your question is a general one so and I understand that it is a question.

369
00:55:25.050 --> 00:55:25.440
Marjorie Luesebrink: To all.

370
00:55:25.680 --> 00:55:30.210
Anna Nacher: Of the panelists right would you like to pose it yourself.

371
00:55:31.200 --> 00:55:39.360
Devin: Sure, can you hear me okay yeah okay um so I was just wondering, you know to what extent these platform experiences are.

372
00:55:39.900 --> 00:55:46.800
Devin: You know, inevitably producing these extreme behaviors I think what we just discussed was sort of along those lines and.

373
00:55:47.790 --> 00:55:59.010
Devin: Somebody mentioned before, my comment i've lost it now, but they sort of also tend to listen elicited emotional response as well, and I just wondered if the panelists would in their individual examples, maybe have some insight on that.

374
00:55:59.910 --> 00:56:02.730
Anna Nacher: Thank you, individual panelists to go ahead.

375
00:56:04.080 --> 00:56:05.160
Anna Nacher: Something maybe with.

376
00:56:06.180 --> 00:56:07.050
Anna Nacher: Rachel know.

377
00:56:08.670 --> 00:56:09.180
Anna Nacher: If you guys.

378
00:56:10.650 --> 00:56:24.570
Rachel Winter: yeah I definitely think that platform design as you noted, is intended to capture the attention and one of the things that can cause prolonged engagement, which is what we're looking for, so we want the advertisers to reach the largest audience possible.

379
00:56:25.980 --> 00:56:44.700
Rachel Winter: Part of the way that they do that is by enabling the formation of these sort of polarized polarized communities that once here within them people tend to just reinforce each other's beliefs and push each other, further to the extreme, so I think that the way that the platform designed.

380
00:56:46.530 --> 00:57:01.470
Rachel Winter: impacts these individual users experiences, is to facilitate the connection with other users with similar views i'm not sure how it necessarily applies to tinder that's something I would have to think about because of.

381
00:57:02.490 --> 00:57:11.940
Rachel Winter: The private nature of the communication on tinder that it there's less I think of a tendency for the formation of these ECHO chambers.

382
00:57:12.480 --> 00:57:18.300
Rachel Winter: But I definitely think that you could see similar things happening on reddit with a dedicated subreddit.

383
00:57:18.780 --> 00:57:34.320
Rachel Winter: Like are the Donald and stuff like that, like they form these insular communities and they're not in there, encouraging healthy debate, but instead are sort of just like bouncing off one another and pushing each other, further to the right or further to the left.

384
00:57:37.980 --> 00:57:49.470
Rachel Winter: Doing so which then encourages people to not only spend more time on the platform, but also to like returned to the platform again and again and again, so I do think it's sort of intentional in the design.

385
00:57:50.640 --> 00:57:57.000
Anna Nacher: Thank you lauren you'd like to add, and then you've already I think said.

386
00:57:57.840 --> 00:58:04.530
Ben Grosser: I could actually speak a lot, I mean, I think I think there's a there's a slightly different flavor to the question, if you don't mind just give a short comment.

387
00:58:05.700 --> 00:58:08.490
Ben Grosser: Because you know I hear their question really is about.

388
00:58:09.540 --> 00:58:10.290
Ben Grosser: Being you know.

389
00:58:11.550 --> 00:58:20.100
Ben Grosser: Is polarization inevitable with these kinds of platforms and I very much believe, the answer is no it's not inevitable.

390
00:58:21.750 --> 00:58:32.490
Ben Grosser: Simply having a social media platform doesn't produce polarization what produces polarization in the current conditions of the platforms we're all embedded in is.

391
00:58:33.270 --> 00:58:42.750
Ben Grosser: The profit motive of the companies and the ideology of growth over everything else, the growth is the ultimate.

392
00:58:43.620 --> 00:59:00.570
Ben Grosser: thing to be seeking and when those two things are put together in the case of a Facebook, for example, you end up with a system whose goal is to keep you on the system, and in that case yeah I think polarization.

393
00:59:01.860 --> 00:59:12.480
Ben Grosser: is often the outcome, because one of the things that keeps people engaged is a polarizing opinion someone you know if you're on a social media platform and it's.

394
00:59:12.900 --> 00:59:21.420
Ben Grosser: A Ford and says focus you on your own metrics and your metric performance, how many likes how many followers and then you.

395
00:59:22.350 --> 00:59:34.020
Ben Grosser: want to see how you activate people to get more likes and followers it doesn't take very long to realize that saying something crazy outrageous is the thing that activates people to react.

396
00:59:34.440 --> 00:59:40.170
Ben Grosser: And so polarization is often the outcome but that doesn't mean systems need to be designed that way system could be designed.

397
00:59:41.520 --> 00:59:43.710
Ben Grosser: For example, in a way that.

398
00:59:44.910 --> 00:59:52.320
Ben Grosser: discourages us rather than encourages us or tries to keep you know make people stay the least amount of time, rather than the most amount of time.

399
00:59:54.570 --> 00:59:55.140
Ben Grosser: what's that.

400
00:59:57.300 --> 00:59:58.260
Ben Grosser: Sorry, I heard a comment.

401
00:59:59.490 --> 01:00:00.000
Okay yeah.

402
01:00:01.590 --> 01:00:02.190
Ben Grosser: So.

403
01:00:03.540 --> 01:00:11.640
Ben Grosser: So anyway, so I don't think it's inevitable i'm actually working on several new projects for an upcoming exhibition and.

404
01:00:12.660 --> 01:00:21.300
Ben Grosser: In August, so stay tuned I actually have a platform that will be a part of that exhibition that maybe addresses that question more directly.

405
01:00:22.080 --> 01:00:36.840
Anna Nacher: Thank you so much i'm looking forward to it, and it is also very uplifting to hear that polarization is not inevitable, I will keep this words as kind of a model for the social media presence and justin would you like to comment on this.

406
01:00:36.870 --> 01:00:39.480
Justin: As well yeah response to the.

407
01:00:40.800 --> 01:00:53.010
Justin: question whether the the alternate reality game platform is designed to encourage extreme behavior um I think the answer is no, but.

408
01:00:53.520 --> 01:01:04.950
Justin: Like with anything, it can be misused and because it has historically been misused it's also really ideal for new form right like you can trace it back to the 80s, at the latest.

409
01:01:07.230 --> 01:01:19.140
Justin: There just hasn't been a lot of time for it to be refined and then co opted and then refined again to prevent misuse and I think that that's where we are right now.

410
01:01:19.710 --> 01:01:32.190
Justin: Now that designers or at least me and i'm telling designers are aware that, like hey this stuff that we're doing is being misappropriated for like very bad ends.

411
01:01:32.850 --> 01:01:37.020
Justin: We have a responsibility to understand how that's happening and try to.

412
01:01:37.590 --> 01:01:53.550
Justin: Not only refine the tools, so that it makes it harder to do that, because obviously the juice out of the bottle we can't put it back in but how can we use these tools to produce counter productive programming either explicitly.

413
01:01:54.600 --> 01:02:01.710
Justin: Content designed to counteract what's being done or content that runs.

414
01:02:02.940 --> 01:02:17.370
Justin: Along opposite philosophical lines and does things like increases participation elections, which is a thing that's been going on for the past couple of years, there are platforms in Spain and Taiwan across South America that use.

415
01:02:18.600 --> 01:02:28.530
Justin: sort of these game logic to actually builds democracies strength to strength to be systems rather the break it down like we're seeing in the United States.

416
01:02:29.670 --> 01:02:33.180
Anna Nacher: Thank you very much, and now question from Atlanta to lauren.

417
01:02:33.180 --> 01:02:33.540
Justin: and

418
01:02:33.600 --> 01:02:36.390
Anna Nacher: Rachel number and i'll do like to ask your question yourself.

419
01:02:38.490 --> 01:02:39.510
Magdalena Regina Tyzlik-Carver: Yes, thank you.

420
01:02:40.920 --> 01:02:49.830
Magdalena Regina Tyzlik-Carver: Thanks so yeah my question really I might, maybe, just to clarify, because my question is really about getting refining the users and.

421
01:02:50.730 --> 01:03:02.790
Magdalena Regina Tyzlik-Carver: And if you know that results in generating that friction that Ben was talking about right so rather than making tinder tinder because, as you say in your paper, the intention of the of the tinder was to.

422
01:03:04.740 --> 01:03:10.410
Magdalena Regina Tyzlik-Carver: was to connect users to new matches by other choices from playing right.

423
01:03:10.740 --> 01:03:20.460
Magdalena Regina Tyzlik-Carver: And so, so obviously it, but it generated something a little bit opposite, in a sense that that the players started to realize that perhaps that kind of is not going to go well.

424
01:03:20.940 --> 01:03:37.710
Magdalena Regina Tyzlik-Carver: In the future, so i'm curious as you talk about the way in which the users respond on other in other social media and i'm curious if they also responded to tinder if they kind of complained or if they sort of you know, had had some.

425
01:03:38.580 --> 01:03:54.090
Magdalena Regina Tyzlik-Carver: Question to tend tend to how I or if they wanted to repair something or their possible sort of algorithmic effect of their choices on who they might be matched with, and so on, I wondered if you had any results or information about that thanks.

426
01:03:55.980 --> 01:04:09.660
Lauren Rouse (she/they): yeah so we didn't particularly look to see if people had reached out directly to tinder for this study and, but I do know that people do try to like play the algorithm in tinder.

427
01:04:10.830 --> 01:04:24.780
Lauren Rouse (she/they): tinder basis itself mostly off of location first, but things will happen like if you are swiping left on mostly people of color the people of color will stop showing up as often and you're like.

428
01:04:25.470 --> 01:04:32.790
Lauren Rouse (she/they): deck for you to look through or if you're swiping more on people who are a certain age they'll start showing up more often and so that's how the algorithm kind of.

429
01:04:33.180 --> 01:04:39.330
Lauren Rouse (she/they): works around, and I do know that, like a lot of people when they were commenting on the reddit.

430
01:04:39.600 --> 01:04:46.440
Lauren Rouse (she/they): What they were really afraid of was being like labeled as like not a good person or being perceived as someone who would do something.

431
01:04:46.650 --> 01:04:52.920
Lauren Rouse (she/they): Like cheat on a partner or cover for someone who is cheating and so it dealt with like a lot of morality issues.

432
01:04:53.250 --> 01:05:04.920
Lauren Rouse (she/they): Additionally, a lot of people, this was run twice so tender swipe it was run the first time in October 2019 and then it was run again last summer I think it was in like August of 2020.

433
01:05:05.640 --> 01:05:11.730
Lauren Rouse (she/they): And so, a lot of people played it twice and were able to like change their answers, because they had.

434
01:05:11.910 --> 01:05:25.200
Lauren Rouse (she/they): known already what it was going to do, once and they were like well I don't like how that answer makes me be perceived so i'm going to change it this time and so that was also kind of their way to call back tinder and out the algorithm as well, so.

435
01:05:32.970 --> 01:05:33.660
Anna Nacher: Would you like to add.

436
01:05:34.170 --> 01:05:35.190
Magdalena Regina Tyzlik-Carver: anything to that.

437
01:05:36.750 --> 01:05:39.000
Rachel Winter: No, I think lauren pretty much covered it.

438
01:05:39.390 --> 01:05:47.550
Anna Nacher: was covered yeah but lauren Thank you so much, and we also have question from from Christian for justin Christian.

439
01:05:47.640 --> 01:05:57.030
Christian Ulrik Andersen: I think I think justin has already kind of addressed what I was asking, so I think I I suggest that move on to Daniel because he's also I.

440
01:05:57.330 --> 01:06:04.110
Anna Nacher: don't know this already I think asked his question, if you mean Daniel Cox, who asked two questions.

441
01:06:04.710 --> 01:06:07.740
Anna Nacher: Okay, yes, so go ahead, if you want.

442
01:06:09.180 --> 01:06:10.770
Anna Nacher: With your question actually doesn't need to think.

443
01:06:10.830 --> 01:06:13.020
Christian Ulrik Andersen: about it sort of we sort of.

444
01:06:13.200 --> 01:06:21.540
Christian Ulrik Andersen: We have different the conversations going on around different topics, so this is perhaps sort of returning a bit to something that we were discussing earlier on.

445
01:06:21.960 --> 01:06:39.900
Christian Ulrik Andersen: But i'm just sort of extremely interested in how in how sort of the act of a protest a is shaped by by social media and and other kinds of sort of not just social media but various kinds of.

446
01:06:40.860 --> 01:06:48.390
Christian Ulrik Andersen: social media media that construct social relations so so I have sort of a sort of an open question of how these.

447
01:06:48.990 --> 01:07:00.990
Christian Ulrik Andersen: How this has changed over the past decade, because a decade ago you saw need rossiter glue been criticizing the sort of so called Twitter revolution said well revolutions or protest.

448
01:07:02.010 --> 01:07:07.890
Christian Ulrik Andersen: tied to the hashtag and now you see something else which is perhaps tied.

449
01:07:08.790 --> 01:07:18.330
Christian Ulrik Andersen: tied to other mechanisms, perhaps some of the mechanisms that that then also describes and I wonder how that how that changes the act of a protest.

450
01:07:19.080 --> 01:07:28.200
Christian Ulrik Andersen: A Ross its own loving they they, for instance criticize the Twitter revolutions, for not having an organized network.

451
01:07:28.650 --> 01:07:38.190
Christian Ulrik Andersen: But, yet you see in in June and some some kind of organized network in this sort of new propaganda that you are outlining justin.

452
01:07:38.460 --> 01:07:57.510
Christian Ulrik Andersen: So what so it's more like sort of this speculative question and what what has changed, and what and what remains the same, and how does that How does that change the protest and sort of the individual's ability to imagine sort of different alternative social future yeah.

453
01:07:59.130 --> 01:08:04.800
Anna Nacher: I pass this this question immediately to panelists, but I would like to chime in because I just written.

454
01:08:06.450 --> 01:08:12.780
Anna Nacher: Practice in Poland and around hashtag on Twitter feminist what was called revolution, and I would like to.

455
01:08:13.260 --> 01:08:25.590
Anna Nacher: briefly comment that this notion of week proudest actually I use the notion of a week province that also a concept, the concept toys, but when by one of the feminists philosophers from Poland, what she said.

456
01:08:26.370 --> 01:08:48.750
Anna Nacher: She called it a week resistance was what she said was that this week resistance is something like you know felt like female kind of social activity which is not spectacular because we tend to you know we tend to associate revolutions, we don't speak spectacular jesters like like like.

457
01:08:50.010 --> 01:08:55.290
Anna Nacher: Like on my spiel or you know the beginning of the French Revolution, but.

458
01:08:56.430 --> 01:09:17.670
Anna Nacher: The majority of the activity around Twitter hashtags, for example, or this everyday digital activities could be named week resistance, like those acts of everyday activity on social media that often go under recognized, because often they are confined with our, for example.

459
01:09:18.750 --> 01:09:20.760
Anna Nacher: chatter box or you know.

460
01:09:22.110 --> 01:09:33.510
Anna Nacher: We can bounce or those those machining ways of intervening so so that that'll be my my very brief comment on is that.

461
01:09:34.230 --> 01:09:44.700
Anna Nacher: As much as we despise the notion of the Twitter revolution is you know kind of a category that was a bit superficial at the time, and I think we should we shouldn't also.

462
01:09:45.660 --> 01:09:57.060
Anna Nacher: Go to the extremes, there is still something to something interesting to look on so yeah sorry about turning in, but that was kind of a topic, I was interested in recently yeah go ahead, no.

463
01:09:59.280 --> 01:10:04.800
Ben Grosser: yeah no thanks and i'm really appreciate hearing that it's I think the.

464
01:10:09.390 --> 01:10:18.000
Ben Grosser: I think a big I mean to me with this makes me think about is that shifts in the focus of a social media platform.

465
01:10:18.690 --> 01:10:23.760
Ben Grosser: can have dramatic effects on how protest plays out and certainly there's you know.

466
01:10:24.420 --> 01:10:35.520
Ben Grosser: Echoing probably some of the critiques have already mentioned the idea of slack activism, the way in which platforms produce a feeling for users, that complaining about a political.

467
01:10:36.390 --> 01:10:44.160
Ben Grosser: issue on social media or collectively complaining has some particular kind of effect but it doesn't necessarily usually doesn't.

468
01:10:44.730 --> 01:10:55.470
Ben Grosser: Just goes into the ether and feeds the system, but after the 2016 presidential election United States Facebook changed its long standing mission statement of.

469
01:10:57.180 --> 01:11:11.970
Ben Grosser: To make the world more open and connected into I don't remember what it is now but it's something about Community to build Community or something like that, and along with that was a platform change which would heavily emphasized the local.

470
01:11:13.050 --> 01:11:23.250
Ben Grosser: To show a lot more local groups in one's feed, and I think at this point that's pretty well acknowledged to have been a primary producer of.

471
01:11:23.940 --> 01:11:43.950
Ben Grosser: The conditions that led to the one six insurrection at the Capitol in the United States, the way in which this kind of extreme focus on the local allows the festering and the organization of individuals into groups around fringe theory and fringe ideas and.

472
01:11:45.330 --> 01:11:54.930
Ben Grosser: You know the more your act your rhythmic feed identifies you as someone interested in a fringe theory, the less it's going to show you alternatives to the fringe theory or.

473
01:11:55.170 --> 01:12:00.090
Ben Grosser: In some cases that i'm talking about reality less it's going to show you a reality, and the more it's going to show you.

474
01:12:01.470 --> 01:12:15.420
Ben Grosser: These are the things I think the the key you know thinking a little bit about two movements that have organized over the last couple of years here one is the the kind of cumin on inspired.

475
01:12:16.770 --> 01:12:36.810
Ben Grosser: interaction organized around what we call the United States in the media, the big lie that trump actually won the election of 2020 and side that one compared to say black lives matter which has had dramatic organization within social media platforms.

476
01:12:37.830 --> 01:12:39.420
Ben Grosser: in ways that have.

477
01:12:40.590 --> 01:12:44.700
Ben Grosser: Affected some some significant refocusing.

478
01:12:45.870 --> 01:12:47.430
Ben Grosser: In the country and.

479
01:12:48.450 --> 01:12:55.800
Ben Grosser: In common with both of them is a combination of extreme interaction on social media but gathering in some way.

480
01:12:56.340 --> 01:13:06.360
Ben Grosser: I think black lives matter is a more of a periodic gathering she went on was kind of a directed, you know the the one six insurrection was a directed gathering towards that particular event.

481
01:13:07.650 --> 01:13:08.040
Ben Grosser: And I.

482
01:13:09.210 --> 01:13:17.580
Ben Grosser: won six insurrection produced what it produced, and we can talk about it in detail, I see it is pretty dramatically different from what black lives matter has produced so far.

483
01:13:18.690 --> 01:13:21.090
Ben Grosser: In terms of its effect on change.

484
01:13:23.130 --> 01:13:25.110
Ben Grosser: So that's maybe, and we could get.

485
01:13:26.370 --> 01:13:30.240
Ben Grosser: Anyway, those are some reactions, I could probably go deep and really analyze but.

486
01:13:31.020 --> 01:13:35.430
Anna Nacher: I thank you so much, it was so interesting to hear the differences and not let's not forget that.

487
01:13:36.270 --> 01:13:47.280
Anna Nacher: The capital events were sort of instigated by kind of alternative platforms like events parlor and we're at the point where we can see the rise of.

488
01:13:48.120 --> 01:13:58.380
Anna Nacher: out right platforms or reactionary platforms so that's also interesting issue in itself unfortunately we've got one minute left so not much.

489
01:13:58.980 --> 01:14:21.060
Anna Nacher: To continue the discussion and I am so pleased, I could I had a chance to moderate this extremely interesting panel Thank you so much for the presentations and thank you very much for your questions that was awesome Thank you very much, see you at another panels Thank you so much.

